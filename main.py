# main.py

# === æ¨™æº–ãƒ©ã‚¤ãƒ–ãƒ©ãƒª ===
from pathlib import Path

# === ã‚µãƒ¼ãƒ‰ãƒ‘ãƒ¼ãƒ†ã‚£ãƒ©ã‚¤ãƒ–ãƒ©ãƒª ===
from rich.console import Console
from rich.table import Table

# === ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« ===
from core.config_loader import load_config
from core.prompt_loader import load_prompt
from core.model_runner import initialize_model, generate_response
from core.output_writer import save_output

console = Console()

CONFIG_PATH = Path("config.yaml")
PROMPT_PATH = Path("prompts/story.txt")
OUTPUT_PATH = Path("outputs/output.txt")

def display_config(config: dict) -> None:
    """
    è¨­å®šå†…å®¹ã‚’ãƒ†ãƒ¼ãƒ–ãƒ«å½¢å¼ã§è¡¨ç¤ºã—ã¾ã™ã€‚
    """
    table = Table(title="ğŸ› ï¸ ãƒ¢ãƒ‡ãƒ«è¨­å®š")
    table.add_column("ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿", style="cyan", no_wrap=True)
    table.add_column("å€¤", style="magenta")
    for key, value in config.items():
        table.add_row(str(key), str(value))
    console.print(table)

def main():
    """
    ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ãƒ¡ã‚¤ãƒ³å‡¦ç†ã€‚
    """
    config = load_config(CONFIG_PATH)
    display_config(config)

    prompt = load_prompt(PROMPT_PATH)
    console.rule("[bold cyan]ğŸ“ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ")
    console.print(prompt, style="white on black")

    llm = initialize_model(config)
    response = generate_response(llm, prompt, config)

    console.rule("[bold green]ğŸ“¤ ç”Ÿæˆçµæœ")
    console.print(response, style="bold white")

    save_output(response, OUTPUT_PATH)

if __name__ == "__main__":
    main()
